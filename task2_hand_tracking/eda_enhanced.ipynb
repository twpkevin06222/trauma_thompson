{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094de820",
   "metadata": {},
   "source": [
    "This notebook is built upon `eda_preliminary.ipynb`, the reason is because after training the object detection model based on the curated data <br> \n",
    "I realised that the validation loss is gradually increasing. This prompts me to rediscover the dataset and check the annotations manually. <br> \n",
    "The following videos has bad annotations with description:\n",
    "<ol>\n",
    "<li> P03_11 -> Bounding box annotations are not aligned with the hand, bounding boxes detects else where </li>\n",
    "<li> P03_12 -> Bounding box annotations are not aligned with the hand, bounding boxes detects else where </li>\n",
    "<li> P04_11 -> Bad quality annotations </li>\n",
    "<li> P04_18 -> Bad quality annotations</li>\n",
    "<li> P04_23 -> Bad quality annotations </li>\n",
    "\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d77031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f023bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def convert_json_to_yolo_txt(\n",
    "    json_path: str,\n",
    "    output_dir: str,\n",
    "    original_img_size: tuple[int, int],\n",
    "    resize_img_size: tuple[int, int] = (1280, 920),\n",
    "    one_category: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Converts a hand bbox annotation JSON file to YOLO format .txt file (one line per bbox):\n",
    "    YOLO format (class x_center y_center width height, all normalized [0,1])\n",
    "    Assumes class 0 for hands. If img_width/height is not given, use video info if available.\n",
    "    \"\"\"\n",
    "    # If output .txt path is not provided, replace .json with .txt\n",
    "    img_name = os.path.basename(json_path).replace(\".json\", \"\")\n",
    "    video_name = os.path.basename(os.path.dirname(json_path))\n",
    "    txt_path = os.path.join(output_dir, f\"{video_name}_{img_name}.txt\")\n",
    "\n",
    "    # First, try reading the image dimensions from the JSON (\"image_width\", \"image_height\")\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    img_width = original_img_size[0]\n",
    "    img_height = original_img_size[1]\n",
    "    img_width_reshape = resize_img_size[0]\n",
    "    img_height_reshape = resize_img_size[1]\n",
    "    img_width_reshape_ratio = img_width_reshape / img_width\n",
    "    img_height_reshape_ratio = img_height_reshape / img_height\n",
    "    lines = []\n",
    "    # The bboxes are usually in \"annotations\": [{\"bbox\": [x, y, w, h], ...}, ...]\n",
    "    for ann in data.get(\"annotations\", []):\n",
    "        bbox = ann.get(\"bbox\")\n",
    "        id = ann.get(\"id\")\n",
    "        if bbox is None or len(bbox) != 4:\n",
    "            continue\n",
    "        x, y, w, h = bbox\n",
    "        x = x * img_width_reshape_ratio\n",
    "        y = y * img_height_reshape_ratio\n",
    "        w = w * img_width_reshape_ratio\n",
    "        h = h * img_height_reshape_ratio\n",
    "        # Convert to YOLO: normalized center_x, center_y, width, height\n",
    "        x_center = (x + w / 2) / img_width_reshape\n",
    "        y_center = (y + h / 2) / img_height_reshape\n",
    "        w_norm = w / img_width_reshape\n",
    "        h_norm = h / img_height_reshape\n",
    "        # Clamp between 0 and 1\n",
    "        x_center = min(max(x_center, 0), 1)\n",
    "        y_center = min(max(y_center, 0), 1)\n",
    "        w_norm = min(max(w_norm, 0), 1)\n",
    "        h_norm = min(max(h_norm, 0), 1)\n",
    "        # class index (0), then the values\n",
    "        if one_category:\n",
    "            lines.append(f\"{0} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "        else:\n",
    "            lines.append(\n",
    "                f\"{id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
    "            )\n",
    "    # only convert the video with valid annotations\n",
    "    if len(lines) > 0:\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_video_frame(\n",
    "    video_path: str,\n",
    "    frame_index: int,\n",
    "    output_dir: str,\n",
    "    resize_img_size: tuple[int, int] = (1280, 920),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Get a frame from a video and save it as a jpg file.\n",
    "    Only fix to jpg file for simplicity. \n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.basename(video_path).replace(\".mp4\", \"\")\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, resize_img_size)\n",
    "    output_path = os.path.join(output_dir, f\"{video_name}_frame_{frame_index:06d}.jpg\")\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9469b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process videos...\n",
      "Skipping video: P03_11 due to bad annotations\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P03_10.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P03_10\n",
      "Finished processing video: P03_10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_28.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_28\n",
      "Finished processing video: P05_28\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P03_08.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P03_08\n",
      "Finished processing video: P03_08\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P04_28.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P04_28\n",
      "Finished processing video: P04_28\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P02_38.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P02_38\n",
      "Finished processing video: P02_38\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_29.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_29\n",
      "Finished processing video: P05_29\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Skipping video: P04_18 due to bad annotations\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P03_42.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P03_42\n",
      "Finished processing video: P03_42\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Skipping video: P04_23 due to bad annotations\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P03_22.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P03_22\n",
      "Finished processing video: P03_22\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P04_29.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P04_29\n",
      "Finished processing video: P04_29\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P03_03.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P03_03\n",
      "Finished processing video: P03_03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P04_21.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P04_21\n",
      "Finished processing video: P04_21\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Skipping video: P04_11 due to bad annotations\n",
      "Skipping video: P03_12 due to bad annotations\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_23.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_23\n",
      "Finished processing video: P05_23\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_02.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_02\n",
      "Finished processing video: P05_02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_05.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_05\n",
      "Finished processing video: P05_05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing video from: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos/P05_01.mp4\n",
      "Annotations found in folder: /home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox/P05_01\n",
      "Finished processing video: P05_01\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# list out all relevelant file paths and directories\n",
    "output_dir = \"/home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/ultralytics_training\"\n",
    "csv_pth = \"./outputs/info_df.csv\"\n",
    "anno_dir = (\n",
    "    \"/home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/bbox\"\n",
    ")\n",
    "video_dir = (\n",
    "    \"/home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/train/videos\"\n",
    ")\n",
    "save_img_dir = \"/home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/ultralytics_training/images\"\n",
    "save_anno_dir = \"/home/kevinteng/Desktop/dataset/trauma_thompson_dataset/task2_hands/ultralytics_training/labels\"\n",
    "resize_img_size = (1280, 920)\n",
    "\n",
    "df = pd.read_csv(csv_pth)\n",
    "# do not include videos with bad annotations\n",
    "video_id_to_skip = [\"P03_11\", \"P03_12\", \"P04_11\", \"P04_18\", \"P04_23\"]\n",
    "\n",
    "error_df = []\n",
    "print(\"Starting to process videos...\")\n",
    "for video_id in df[\"video_id\"]:\n",
    "    # skip videos with bad annotations\n",
    "    if video_id in video_id_to_skip:\n",
    "        print(f\"Skipping video: {video_id} due to bad annotations\")\n",
    "        continue\n",
    "    video_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
    "    anno_path = os.path.join(anno_dir, f\"{video_id}\")\n",
    "    print(f\"Processing video from: {video_path}\")\n",
    "    print(f\"Annotations found in folder: {anno_path}\")\n",
    "    # the video width and height for resizing\n",
    "    width = df.loc[df[\"video_id\"] == video_id, \"width\"].values[0] \n",
    "    height = df.loc[df[\"video_id\"] == video_id, \"height\"].values[0]\n",
    "    # get split status\n",
    "    split = df.loc[df[\"video_id\"] == video_id, \"split\"].values[0]\n",
    "    # create save directory\n",
    "    save_img_dir_split = os.path.join(save_img_dir, split)\n",
    "    save_anno_dir_split = os.path.join(save_anno_dir, split)\n",
    "    if not os.path.exists(save_img_dir_split):\n",
    "        os.makedirs(save_img_dir_split, exist_ok=True)\n",
    "    if not os.path.exists(save_anno_dir_split):\n",
    "        os.makedirs(save_anno_dir_split, exist_ok=True)\n",
    "    # loop through the annotations correlated to the video id \n",
    "    # the annotations needed to be sorted to ensure the frame index is in sequence order\n",
    "    for anno_json in sorted(glob(os.path.join(anno_path, \"*.json\"))):\n",
    "        frame_index = int(os.path.basename(anno_json).replace(\".json\", \"\").split(\"_\")[-1])\n",
    "        # convert the annotation to yolo format\n",
    "        anno_exist = convert_json_to_yolo_txt(\n",
    "            anno_json,\n",
    "            save_anno_dir_split,\n",
    "            original_img_size=(width, height),\n",
    "            resize_img_size=resize_img_size,\n",
    "            one_category=False\n",
    "        )\n",
    "        # skip retriveing the video frame with the annotation is not valid\n",
    "        if not anno_exist:\n",
    "            continue\n",
    "        try:\n",
    "            # get the video frame and resize them\n",
    "            get_video_frame(\n",
    "                video_path,\n",
    "                frame_index,\n",
    "                output_dir=save_img_dir_split,\n",
    "                resize_img_size=resize_img_size\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {video_id} at frame {frame_index}: {e}\")\n",
    "            # log the error frames for inspection\n",
    "            log_df = pd.DataFrame({\"video_id\": [video_id], \"frame_index\": [frame_index]})\n",
    "            error_df.append(log_df)\n",
    "            # no need to have converted .txt file if there is not frame\n",
    "            continue\n",
    "\n",
    "    print(f\"Finished processing video: {video_id}\")\n",
    "    print(\"-\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
